###### 压缩特征的重建  

我们可以利用下式将压缩特征来重建原特征。  

![](http://upload-images.jianshu.io/upload_images/5983416-071205f80d8516a7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中x^(i)^~approx~ ≈ x^(i)^。  

![](http://upload-images.jianshu.io/upload_images/5983416-d3495178b3520f20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

###### 选择主成分数量  

通常，我们一般在满足下式的情况下选择尽可能小的K值。  

![](http://upload-images.jianshu.io/upload_images/5983416-f2b593d81febc8b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，上式的分子为投影误差平方和均值（Average Squared Projection Error）；
分母为Total Variation in The Data。  

我们也可以用“99% of variance is retained”来描述上式。       

我们实现上述方法的算法为：  

1. 令K = 1；  
2. 利用PCA算法得到U~reduce~ , z^(1)^, ···, z^(m)^, x^(1)^~approx~ ,···, x^(m)^~approx~ ；  
3. 检查是否满足下式：  

![](http://upload-images.jianshu.io/upload_images/5983416-d0b7759e92d6b176.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

4. 如果第3步不满足，则令K = 2, 3，···，继续运行第1\~3步，直至满足第3步的不等式。  

但这种算法运行效率不高。因此，我们可以在Octave或MATLAB中使用svd()函数，我们可以得到S矩阵：  

![](http://upload-images.jianshu.io/upload_images/5983416-13ac72442202ce0c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以使用该矩阵计算：  

![](http://upload-images.jianshu.io/upload_images/5983416-efd01bdbbd6b5c5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

即：  

![](http://upload-images.jianshu.io/upload_images/5983416-6bd9bc95fcbc716b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在使用这个算法时，我们仍然令K = 1, 2, 3, ···, 直至满足上述不等式。  

###### 主成分分析算法应用  

在监督学习中，对于数据集{(x^(1)^, y^(1)^), ···, (x^(m)^, y^(m)^)}，其中x^(i)^ ∈ R^100000^。  

我们可提取出无标记的数据集作为输入数据：{x^(1)^, ···, x^(m)^}，其中x^(i)^ ∈ R^100000^。利用PCA算法对该数据集进行降维操作得到：{z^(1)^, ···, z^(m)^}，其中x^(i)^ ∈ R^1000^。从而我们得到一个新的数据集{(z^(1)^, y^(1)^), ···, (z^(m)^, y^(m)^)}，其中z^(i)^ ∈ R^1000^。   

通过上述方法，我们可以提高监督学习的运行速度。       

注：对于x^(i)^ -> z^(i)^映射关系，我们只能在训练集上使用PCA算法，但这种映射关系也能应用于交叉验证集和测试集。     

------------------------------------  

对于PCA算法，其可以压缩数据节省存储空间和提高学习算法的运行速度，以及将高维度的数据集降为低维度，从而将数据集可视化。   

但对于PCA算法，我们不推荐将其用于防止过拟合问题。虽然PCA算法对于防止过拟合问题可能运行得不错，但我们仍然推荐使用正则化来防止过拟合问题。因为使用PCA算法可能会丢失一些重要的信息。    

-----------------------------------  

PCA算法不应该直接用于机器学习系统设计过程中。我们应该考虑原始特征变量，在出现存储空间占用过多或算法运行过慢等情况时，我们才有必要考虑使用PCA算法。
